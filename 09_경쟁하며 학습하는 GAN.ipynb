{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54b3d11",
   "metadata": {},
   "source": [
    "# 학습 목표\n",
    "GAN을 이용해 원하는 이미지를 생성한다.\n",
    "\n",
    "\n",
    "\n",
    "# 목차\n",
    "\n",
    "- GAN의 기초\n",
    "- GAN으로 새로운 패션 아이템 생성하기\n",
    "- cGAN으로 생성 제어하기\n",
    "\n",
    "\n",
    "\n",
    "### 9.1 GAN 기초\n",
    "\n",
    "**GAN(=Generative Adversarial Network)** 직역하면 적대적 생성 신경망이다. 단어를 하나씩 뜯어서 이해하면 편하다.\n",
    "1. **Generative** : GAN은 생성을 하는 모델이다. CNN, RNN과는 달리 GNN은 새로운 이미지나 음성을 **창작**하도록 고안되었다.\n",
    "2. **Adversarial** : GAN은 적대적으로 학습한다. 가짜 이미지를 생성하는 **생성자**와 이미지의 진위를 판별하는 **판별자**가 번갈아 학습하며 경쟁적으로 학습을 진행한다.\n",
    "3. **Network** : GAN은 인공 신경망 모델이다. 생성자, 판별자가 모두 신경망으로 되어있다.\n",
    "\n",
    "GAN은 비지도학습 방식이다. 비지도학습이 미래지향적이라는 평가를 받는 이유는 대부분의 데이터에는 정답(label)이 없기 때문이다. 비지도학습은 사람의 손길을 최소화하며 학습할 수 있다.\n",
    "\n",
    "\n",
    "#### 9.1.1 생성자와 판별자\n",
    "- **생성자** : 무작위 텐서로부터 여러 가지 형태의 가짜 이미지를 생성.\n",
    "- **판별자** : 진짜 이미지와 가짜 이미지를 구분.\n",
    "\n",
    "학습이 진행되며 생성자는 판별자를 속이기 위해 점점 정밀한 가짜 이미지를 생성하고, 판별자는 학습 데이터에서 가져온 진짜 이미지와 생성자가 만든 가짜 이미지를 점점 더 잘 구별하게 된다.\n",
    "\n",
    "> 💡 참고 링크 : [GAN의 기초](https://velog.io/@tobigs-gm1/basicofgan)\n",
    "\n",
    "---\n",
    "\n",
    "### 9.2. GAN으로 새로운 패션 아이템 생성하기\n",
    "#### 9.2.1 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edd23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 import\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f36d1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 장치를 사용합니다:  cpu\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"다음 장치를 사용합니다: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54f5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋 가져오기\n",
    "# Fashion MNIST 데이터셋\n",
    "trainset = datasets.FashionMNIST('./.data',\n",
    "                                train = True,\n",
    "                                download = True,\n",
    "                                transform = transforms.Compose([\n",
    "                                    transforms.ToTensor(), # 텐서로 바꿔주기\n",
    "                                    transforms.Normalize((0.5,), (0.5,)) # 정규화\n",
    "                                ]))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eefa97",
   "metadata": {},
   "source": [
    "#### 9.2.2 생성자와 판별자 구현\n",
    "이제까지는 `nn.Module`클래스를 상속받는 클래스로 정의했기 때문에 모델의 복잡한 동작들을 함수로 정의 가능했다. 하지만 이번 생성자, 판별자는 가독성을 위해 최대한 간단하게 만들고자 한다.\n",
    "\n",
    "`Sequential` 클래스로 신경망을 이루는 각 층에서 수행할 연산들을 입력받아 차례로 실행하고자 한다. -> `__init__()`과 `forward()` 함수를 동시에 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자(Generator)\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(64, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 784), # 결과값이 Fashion MINST 이미지와 같은 차원의 텐서가 되어야함.\n",
    "    nn.Tanh() # 탄젠트 함수 생각하면됨. 값을 -1~1 사이로 압축해줌.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8408d",
   "metadata": {},
   "source": [
    "판별자에서는 ReLU가 아니라 **Leaky ReLU** 활성화 함수를 사용한다.\n",
    "\n",
    "Leaky ReLU활성화 함수는 약간의 음의 기울기도 다음 층에 전달하는 역할을 하는데, 이렇게 하면 판별자에서 계산된 기울기가 0 대신 약한 음수로 전환되며 **생성자에 더 강하게 전달**되기 때문이다.\n",
    "\n",
    "생성자가 학습하기 위해 판별자로부터 **기울기롤 효과적으로 전달**받아야 하기 때문에 중요하다!\n",
    "\n",
    "![ReLU와 LeakyReLU 차이](https://github.com/kjsoo-1010/pytorch_deeplearning/blob/main/9_ReLU_LeakyReLU.png?raw=true)\n",
    "[이미지 출처](https://atcold.github.io/pytorch-Deep-Learning/ko/week11/11-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c78e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자(Discriminator)\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(256, 1), # 진짜/가짜 로 결정이 되기 떄문에 최종 출력값 = 1\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba561f",
   "metadata": {},
   "source": [
    "#### 9.2.3 GAN 학습 구현\n",
    "생성자와 판별자 학습에 쓰일 오차 함수와 최적화 알고리즘을 각각 정의해준다.\n",
    "\n",
    "- 오차 함수 : 레이블이 가짜/진짜 2가지 뿐이므로 BCE(이진 교차 엔트로피)를 사용.\n",
    "- 최적화 함수 : Adam (제일 무난하고 빠르다!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ede954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치 지정 장치에 보내기\n",
    "D = D.to(DEVICE)\n",
    "G = G.to(DEVICE)\n",
    "\n",
    "# 오차 함수 : 진짜/가짜 두 종류니까 BCE\n",
    "# 최적화 함수 : Adam\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr = 0.002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3abe746",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500], d_loss: 0.0000, g_loss: 100.0000, D(x): 1.00, D(G(z)): 0.00\n",
      "Epoch [1/500], d_loss: 0.0000, g_loss: 100.0000, D(x): 1.00, D(G(z)): 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m total_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      4\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mreshape(BATCH_SIZE, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# '진짜'와 '가짜' 레이블 생성\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbands\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습시키는 반복문 시작\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE) # batch 사이즈로 텐서 크기 바꿔주기\n",
    "        \n",
    "        ### 1. '진짜'와 '가짜' 레이블 생성\n",
    "        # 생성자가 만든 데이터 = zeros() 로 0으로 채워서 라벨링 해주기\n",
    "        # Fashion MINST 데이터 = ones() 로 1로 채워서 라벨링 해주기\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "        \n",
    "        ### 2. 판별자가 진짜 이미지를 진짜로 인식하는 오차를 예산\n",
    "        outputs = D(images) # 실제 이미지 -> 판별자 신경망 결과값\n",
    "        d_loss_real = criterion(outputs, real_labels) # 진짜 레이블간의 오차 계산\n",
    "        real_score = outputs\n",
    "        \n",
    "        ### 3. 생성자 동작 정의\n",
    "        # 생성자는 정규분포로부터 생성한 무작위 텐서 -> 실제 이미지와 차원 같은 텐서 배출\n",
    "        z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        ### 4. 판별자가 가짜 이미지를 가짜로 인식하는 오차를 계산\n",
    "        # 생성자 이미지(fake_images) -> 판별자에 입력 -> 오차 계산\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        ### 5. 진짜와 가짜 이미지를 갖고 낸 오차를 더해서 판별자의 오차 계산\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # 역전파로 판별자 모델 학습 진행 -> 판별자 학습!\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        ### 6. 생성자 학습 차례\n",
    "        # 생성자가 판별자를 속였는지에 대한 오차를 계산\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images) # 생성자의 결과물을 다시 판별자에 입력시켜\n",
    "        g_loss = criterion(outputs, real_labels) # 결과물과 1 사이 오차 최소화하는 방식으로 학습 진행\n",
    "        \n",
    "        ### 7. 역전파로 생성자 학습 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    ### 8. 학습 진행 알아보기\n",
    "    # d_loss = 판별자 오차, g_loss = 생성자 오차\n",
    "    # D(x) = 진짜를 진짜로 인식한 '정확도'\n",
    "    # D(G(z)) = 가짜를 진짜로 인식한 정확도\n",
    "    print('Epoch [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "          .format(epoch, EPOCHS, d_loss.item(), g_loss.item(), \n",
    "                  real_score.mean().item(), fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 끝난 생성자 결과물 확인\n",
    "z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "fake_images = G(z)\n",
    "for i in range(10):\n",
    "    fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i],(28, 28))\n",
    "    plt.imshow(fake_images_img, cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450ada2",
   "metadata": {},
   "source": [
    "#### 9.2.4 결과물 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf824c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(BATCH_SIZE, 64).to(DEVICE)\n",
    "fake_images = G(z)\n",
    "\n",
    "for i in range(10):\n",
    "    fake_images_img = np.reshape(fake_images.data.cpu().numpy()[i], (28, 28))\n",
    "    plt.imshow(fake_images_img, cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487df2c",
   "metadata": {},
   "source": [
    "![GAN 결과 이미지](https://github.com/kjsoo-1010/pytorch_deeplearning/blob/main/9_GAN_image.png?raw=true)\n",
    "\n",
    "---\n",
    "\n",
    "### 9.3 cGAN으로 생성 제어하기\n",
    "GAN가 더  쓸모 있으려면 무작위 생성보다는 **사용자가 원하는 이미지**를 생성하는 기능을 제공해야한다.\n",
    "\n",
    "#### 9.3.1 cGAN으로 원하는 이미지 생성하기\n",
    "앞에서 한 GAN 모델은 '패션 아이템 종류 중 무엇을 생성하라'라는 로직이 없었다.\n",
    "\n",
    "`무작위 벡터 입력 -> 무작위 패션 아이템 출력`\n",
    "\n",
    "즉, 사용자가 원하는 패션 아이템을 생성하는 능력이 없다.\n",
    "이를 보완해 출력할 아이템의 종류를 사용자로부터 입력받아 그에 해당하는 이미지를 생성하는 모델이 **조건부 GAN**(=cGAN).\n",
    "\n",
    "\n",
    "![cGAN 모델 구조](https://github.com/kjsoo-1010/pytorch_deeplearning/blob/main/9_cGAN_model.png?raw=true)\n",
    "\n",
    "필요한 라이브러리 임포트, 하이퍼파라미터 설정, 데이터 로딩 부분은 GAN과 같다.\n",
    "\n",
    "#### 9.3.2 조건부 생성자와 판별자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 (Generator)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256), # 왜 110개? -> 100 + 10(레이블 정보)\n",
    "            # nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
    "            # inplace = True -> 입력을 복사하지 않고 바로 조작한다는 뜻\n",
    "            nn.LeakyReLU(0.2, inplace=True), \n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels): # 입력과 레이블 정보까지 2가지 입력 받음.\n",
    "        # 배치x1 크기의 배치x10의 연속적인 텐서로 전환\n",
    "        c = self.embed(labels)\n",
    "        \n",
    "        # cat() : 두 벡터를 두 번째 인수 차원에 대해 이어붙이는 연산 실행.\n",
    "        x = torch.cat([z, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7daac",
   "metadata": {},
   "source": [
    "> 💡 참고 링크 : [nn.Embedding()](https://wikidocs.net/64779)\n",
    "\n",
    "레이블이 주어졌을때 가짜인 확률과 진짜인 확률을 추정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 (Discriminator)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        # 성능 늘리기 위해 드롭아웃 계층 2개 더 추가.\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024), # 784 + 10(레이블 정보 전달)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1264e",
   "metadata": {},
   "source": [
    "#### 9.3.3 cGAN 학습 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스를 만들고 모델의 가중치를 지정한 장치로 보내기\n",
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "\n",
    "# 오차 함수,최적화 함수 앞과 동일\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr =0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr =0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "     # 그냥 GAN에선 라벨이 필요 없어 (images, _) 였는데, 이번엔 받아서 사용.\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # 진짜/가짜 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산 (데이터셋 레이블 입력)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = D(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # 무작위 텐서 생성 = g_label\n",
    "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE)\n",
    "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE)\n",
    "        fake_images = G(z, g_label) # 무작위 텐서와 입력 z 로 가짜 이미지 생성\n",
    "        \n",
    "        # 판별자에게 가짜 이미지 입력.\n",
    "        # outputs = (가짜 이미지, 그에 대한 레이블값)를 판별한 값\n",
    "        outputs = D(fake_images, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels) # 오차 계산\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # loss_real = 진짜 이미지 넣었을 때 오차\n",
    "        # loss_fake = 가짜 이미지 넣었을 때 오차\n",
    "        d_loss = d_loss_real + d_loss_fake # 총 오차\n",
    "        \n",
    "        # 역전파로 판별자 학습 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 아까 생성해둔 z와 g_label로 다시 이미지 생성 => 판별자 속였나?\n",
    "        # 생성자, 판별자 둘 다 g_label을 라벨로 받기\n",
    "        fake_images = G(z, g_label)\n",
    "        outputs = D(fake_images, g_label)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "        # 못 속인 만큼 생성자 학습 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    print('이폭 [{}/{}] d_loss:{:.4f} g_loss: {:.4f} D(x):{:.2f} D(G(z)):{:.2f}'\n",
    "          .format(epoch,\n",
    "                  EPOCHS,\n",
    "                  d_loss.item(),\n",
    "                  g_loss.item(),\n",
    "                  real_score.mean().item(),\n",
    "                  fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f623898",
   "metadata": {},
   "source": [
    "이폭 [0/300] d_loss:0.3160 g_loss: 6.8871 D(x):0.89 D(G(z)):0.04\n",
    "이폭 [1/300] d_loss:0.5910 g_loss: 3.9762 D(x):0.87 D(G(z)):0.19\n",
    "이폭 [2/300] d_loss:0.3091 g_loss: 4.8783 D(x):0.92 D(G(z)):0.08\n",
    "이폭 [3/300] d_loss:0.1595 g_loss: 4.3155 D(x):0.95 D(G(z)):0.06\n",
    "이폭 [4/300] d_loss:0.5849 g_loss: 3.0070 D(x):0.78 D(G(z)):0.13\n",
    "...\n",
    "이폭 [295/300] d_loss:1.2423 g_loss: 1.0166 D(x):0.63 D(G(z)):0.43\n",
    "이폭 [296/300] d_loss:1.3765 g_loss: 0.9225 D(x):0.49 D(G(z)):0.44\n",
    "이폭 [297/300] d_loss:1.2616 g_loss: 0.8626 D(x):0.56 D(G(z)):0.45\n",
    "이폭 [298/300] d_loss:1.2170 g_loss: 0.8461 D(x):0.57 D(G(z)):0.43\n",
    "이폭 [299/300] d_loss:1.1471 g_loss: 1.2162 D(x):0.60 D(G(z)):0.38\n",
    "\n",
    "\n",
    "#### 9.3.4 결과물 시각화\n",
    "\n",
    "`torch.full(텐서 크기, 텐서 원소 초기화할 값)` : 새로운 텐서를 만드는 함수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만들고 싶은 아이템 생성하고 시각화하기\n",
    "item_number = 9 # 아이템 번호 : 부츠\n",
    "z = torch.randn(1, 100).to(DEVICE) # 배치 크기 1\n",
    "\n",
    "# g_label = 지정한 아이템 번호\n",
    "g_label = torch.full((1,), item_number, dtype=torch.long).to(DEVICE)\n",
    "sample_images = G(z, g_label) # 이미지 생성\n",
    "\n",
    "sample_images_img = np.reshape(sample_images.data.cpu().numpy()\n",
    "                               [0],(28, 28))\n",
    "plt.imshow(sample_images_img, cmap = 'gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
